version: "3.8"

services:
  gpu-matmul:
    image: pytorch/pytorch:2.8.0-cuda12.9-cudnn9-runtime
    container_name: gpu-matmul
    # Enable NVIDIA GPUs (Compose v3)
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    restart: false
    # manually-set devices
    devices:
      - /dev/nvidia0:/dev/nvidia0:Z
      - /dev/nvidiactl:/dev/nvidiactl:Z
      - /dev/nvidia-uvm:/dev/nvidia-uvm:Z
      - /dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools:Z
      - /dev/nvidia-caps/nvidia-cap1:/dev/nvidia-caps/nvidia-cap1:Z
      - /dev/nvidia-caps/nvidia-cap2:/dev/nvidia-caps/nvidia-cap2:Z
      
    environment:
      # Set which GPUs to expose; "all" or comma-separated GPU indices (e.g. "0,1")
      NVIDIA_VISIBLE_DEVICES: ${NVIDIA_VISIBLE_DEVICES:-all}
      NVIDIA_DRIVER_CAPABILITIES: ${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
      # Your script's "amount" (examples: "10000" or "75%")
      AMOUNT: ${AMOUNT:-10000}
      # Optional: dtype for your tensors (float16|float32|float64)
      DTYPE: ${DTYPE:-float32}
    volumes:
      # Mount your script (adjust left path to where your file is)
      - ./main.py:/app/main.py:ro
    working_dir: /app
    command: ["python", "/app/main.py", "--amount", "${AMOUNT}", "--dtype", "${DTYPE}"]
